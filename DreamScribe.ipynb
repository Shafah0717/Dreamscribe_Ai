{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wmbi2Wrra6vS"
      },
      "outputs": [],
      "source": [
        "# @title üì¶ Install Required Packages\n",
        "%%capture\n",
        "# Install core packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install diffusers transformers accelerate\n",
        "!pip install streamlit python-dotenv\n",
        "!pip install gtts pygame pillow opencv-python\n",
        "!pip install moviepy imageio imageio-ffmpeg\n",
        "!pip install requests pathlib2\n",
        "!pip install groq\n",
        "\n",
        "# Try to install xformers for memory optimization\n",
        "try:\n",
        "    !pip install xformers\n",
        "    print(\"‚úÖ XFormers installed for memory optimization\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è XFormers not available, using standard attention\")\n",
        "\n",
        "print(\"‚úÖ All packages installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîß Setup Environment & Install Packages\n",
        "%%capture\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Install required packages\n",
        "!pip install streamlit\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install diffusers transformers accelerate\n",
        "!pip install pillow numpy matplotlib\n",
        "!pip install pyngrok  # For exposing Streamlit to public URL\n",
        "!pip install python-dotenv groq\n",
        "\n",
        "print(\"‚úÖ All packages installed!\")\n",
        "\n",
        "# Setup environment\n",
        "os.environ['STREAMLIT_SERVER_PORT'] = '8501'\n",
        "os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üöÄ Device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n"
      ],
      "metadata": {
        "id": "aHnVG52HbFfA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get update -y\n",
        "!apt-get install ffmpeg -y  # ‚Üê Critical for video generation\n",
        "\n",
        "# Install Python packages\n",
        "!pip install gtts\n",
        "!pip install moviepy\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install pydub\n",
        "\n",
        "print(\"‚úÖ All audio/video dependencies installed!\")"
      ],
      "metadata": {
        "id": "dggALj8dbOfU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Launch Modular Dream Cinema Studio\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Check files exist\n",
        "required_files = ['audio_creator.py', 'video_assembler.py', 'dream_processor.py', 'modular_dream_app.py']\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"‚úÖ {file}\")\n",
        "    else:\n",
        "        print(f\"‚ùå {file} missing\")\n",
        "\n",
        "# Ngrok setup\n",
        "ngrok_token = \"\"\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# Launch modular app\n",
        "def run_modular_app():\n",
        "    subprocess.run(['streamlit', 'run', 'complete_dream_cinema.py', '--server.port=8501', '--server.address=0.0.0.0'])\n",
        "\n",
        "print(\"üöÄ Starting Modular Dream Cinema Studio...\")\n",
        "streamlit_thread = threading.Thread(target=run_modular_app)\n",
        "streamlit_thread.daemon = True\n",
        "streamlit_thread.start()\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"üåê Modular Dream Cinema: {public_url}\")\n",
        "print(\"üéØ Features:\")\n",
        "print(\"   - Professional modular architecture\")\n",
        "print(\"   - Separated audio_creator.py module\")\n",
        "print(\"   - Separated video_assembler.py module\")\n",
        "print(\"   - Separated dream_processor.py module\")\n",
        "print(\"   - Clean, maintainable code structure\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8853AiAfbWbt",
        "outputId": "c0258be0-ee86-419d-c12f-f3178c73bf8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ audio_creator.py\n",
            "‚úÖ video_assembler.py\n",
            "‚úÖ dream_processor.py\n",
            "‚ùå modular_dream_app.py missing\n",
            "üöÄ Starting Modular Dream Cinema Studio...\n",
            "üåê Modular Dream Cinema: NgrokTunnel: \"https://524fcb067462.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "üéØ Features:\n",
            "   - Professional modular architecture\n",
            "   - Separated audio_creator.py module\n",
            "   - Separated video_assembler.py module\n",
            "   - Separated dream_processor.py module\n",
            "   - Clean, maintainable code structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üéµ Create Audio Creator Module\n",
        "audio_creator_code = '''\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "class AudioCreator:\n",
        "    \"\"\"Professional audio generation using gTTS\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.output_dir = \"/tmp/dream_audio\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        print(\"üéµ AudioCreator initialized\")\n",
        "\n",
        "    def create_narration(self, text, voice_style=\"mystical\", language=\"en\"):\n",
        "        \"\"\"Create narration audio from text\"\"\"\n",
        "        try:\n",
        "            print(f\"üéôÔ∏è Creating narration: {len(text)} characters\")\n",
        "\n",
        "            # Voice style configurations\n",
        "            voice_configs = {\n",
        "                \"mystical\": {\"tld\": \"co.uk\", \"slow\": True},\n",
        "                \"dramatic\": {\"tld\": \"com\", \"slow\": False},\n",
        "                \"gentle\": {\"tld\": \"ca\", \"slow\": True},\n",
        "                \"epic\": {\"tld\": \"com.au\", \"slow\": False}\n",
        "            }\n",
        "\n",
        "            config = voice_configs.get(voice_style, voice_configs[\"mystical\"])\n",
        "\n",
        "            # Create TTS object\n",
        "            tts = gTTS(\n",
        "                text=text,\n",
        "                lang=language,\n",
        "                slow=config[\"slow\"],\n",
        "                tld=config[\"tld\"]\n",
        "            )\n",
        "\n",
        "            # Save to file\n",
        "            timestamp = int(time.time())\n",
        "            filename = f\"narration_{voice_style}_{timestamp}.mp3\"\n",
        "            filepath = os.path.join(self.output_dir, filename)\n",
        "\n",
        "            tts.save(filepath)\n",
        "\n",
        "            if os.path.exists(filepath):\n",
        "                file_size = os.path.getsize(filepath)\n",
        "                print(f\"‚úÖ Audio created: {filename} ({file_size} bytes)\")\n",
        "                return filepath\n",
        "            else:\n",
        "                print(\"‚ùå Audio file not created\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Audio creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_background_music(self, duration=30, mood=\"ambient\"):\n",
        "        \"\"\"Placeholder for background music generation\"\"\"\n",
        "        # Could integrate with music generation APIs\n",
        "        print(f\"üéµ Background music placeholder: {duration}s, {mood} mood\")\n",
        "        return None\n",
        "\n",
        "# Test function\n",
        "def test_audio_creator():\n",
        "    creator = AudioCreator()\n",
        "    test_audio = creator.create_narration(\"Hello, this is a test narration.\", \"mystical\")\n",
        "    return test_audio is not None\n",
        "'''\n",
        "\n",
        "with open('audio_creator.py', 'w') as f:\n",
        "    f.write(audio_creator_code)\n",
        "\n",
        "print(\"‚úÖ audio_creator.py created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXkPLJJ1bZfW",
        "outputId": "bad7e136-a5f3-449b-d689-0ee92ea304f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ audio_creator.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üé¨ Create Video Assembler Module\n",
        "video_assembler_code = '''\n",
        "import os\n",
        "import time\n",
        "from moviepy.editor import (\n",
        "    ImageSequenceClip, AudioFileClip, concatenate_videoclips,\n",
        "    CompositeVideoClip, TextClip, ColorClip\n",
        ")\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "\n",
        "class VideoAssembler:\n",
        "    \"\"\"Professional video assembly using MoviePy\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.output_dir = \"/tmp/dream_videos\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        self.temp_dir = \"/tmp/dream_video_temp\"\n",
        "        os.makedirs(self.temp_dir, exist_ok=True)\n",
        "        print(\"üé¨ VideoAssembler initialized\")\n",
        "\n",
        "    def create_video(self, image_paths, audio_path, scenes, dream_script):\n",
        "        \"\"\"Create complete video from images, audio, and metadata\"\"\"\n",
        "        try:\n",
        "            print(f\"üé¨ Creating video from {len(image_paths)} images\")\n",
        "\n",
        "            if not image_paths:\n",
        "                return self._create_video_placeholder(scenes, dream_script)\n",
        "\n",
        "            # Save PIL Images to temporary files if needed\n",
        "            temp_image_files = []\n",
        "            for i, img_path in enumerate(image_paths):\n",
        "                if isinstance(img_path, str) and os.path.exists(img_path):\n",
        "                    # Already a file path\n",
        "                    temp_image_files.append(img_path)\n",
        "                else:\n",
        "                    # PIL Image object - save to temp file\n",
        "                    temp_path = os.path.join(self.temp_dir, f\"scene_{i}.png\")\n",
        "                    if hasattr(img_path, 'save'):  # PIL Image\n",
        "                        img_path.save(temp_path, \"PNG\")\n",
        "                        temp_image_files.append(temp_path)\n",
        "                        print(f\"   Saved PIL image to: {temp_path}\")\n",
        "\n",
        "            if not temp_image_files:\n",
        "                print(\"‚ùå No valid image files\")\n",
        "                return None\n",
        "\n",
        "            # Create video clips\n",
        "            clips = self._create_image_clips(temp_image_files, scenes)\n",
        "\n",
        "            if not clips:\n",
        "                print(\"‚ùå No video clips created\")\n",
        "                return None\n",
        "\n",
        "            # Combine clips\n",
        "            main_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "            print(f\"‚úÖ Video assembled: {main_video.duration:.1f}s\")\n",
        "\n",
        "            # Add audio if available\n",
        "            if audio_path and os.path.exists(audio_path):\n",
        "                main_video = self._add_audio_to_video(main_video, audio_path)\n",
        "\n",
        "            # Add title overlay\n",
        "            main_video = self._add_title_overlay(main_video, dream_script)\n",
        "\n",
        "            # Export final video\n",
        "            output_path = self._export_video(main_video, dream_script)\n",
        "\n",
        "            return output_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Video creation failed: {e}\")\n",
        "            return self._create_video_placeholder(scenes, dream_script)\n",
        "\n",
        "    def _create_image_clips(self, image_files, scenes):\n",
        "        \"\"\"Convert image files to video clips\"\"\"\n",
        "        clips = []\n",
        "\n",
        "        for i, img_file in enumerate(image_files):\n",
        "            try:\n",
        "                duration = scenes[i].get(\"duration\", 4) if i < len(scenes) else 4\n",
        "\n",
        "                # Create image clip\n",
        "                clip = ImageSequenceClip([img_file], durations=[duration])\n",
        "\n",
        "                # Add fade effects\n",
        "                clip = clip.fadein(0.5).fadeout(0.5)\n",
        "\n",
        "                clips.append(clip)\n",
        "                print(f\"   ‚úÖ Clip {i+1}: {duration}s\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå Failed to create clip {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return clips\n",
        "\n",
        "    def _add_audio_to_video(self, video, audio_path):\n",
        "        \"\"\"Add audio track to video\"\"\"\n",
        "        try:\n",
        "            print(\"üéµ Adding audio to video...\")\n",
        "\n",
        "            audio = AudioFileClip(audio_path)\n",
        "            print(f\"   Audio: {audio.duration:.1f}s\")\n",
        "            print(f\"   Video: {video.duration:.1f}s\")\n",
        "\n",
        "            # Sync audio and video lengths\n",
        "            if audio.duration > video.duration:\n",
        "                audio = audio.subclip(0, video.duration)\n",
        "                print(\"   ‚úÇÔ∏è Audio trimmed to match video\")\n",
        "            elif audio.duration < video.duration:\n",
        "                # Loop audio to match video length\n",
        "                loops = int(video.duration / audio.duration) + 1\n",
        "                audio_loops = [audio] * loops\n",
        "                extended_audio = concatenate_videoclips(audio_loops)\n",
        "                audio = extended_audio.subclip(0, video.duration)\n",
        "                print(f\"   üîÑ Audio looped {loops} times\")\n",
        "\n",
        "            video_with_audio = video.set_audio(audio)\n",
        "            print(\"‚úÖ Audio synchronized\")\n",
        "\n",
        "            return video_with_audio\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Audio integration failed: {e}\")\n",
        "            return video\n",
        "\n",
        "    def _add_title_overlay(self, video, dream_script):\n",
        "        \"\"\"Add title text overlay\"\"\"\n",
        "        try:\n",
        "            title = dream_script.get(\"title\", \"Dream Vision\")\n",
        "            print(f\"üìù Adding title: '{title}'\")\n",
        "\n",
        "            # Create title clip\n",
        "            title_clip = TextClip(\n",
        "                title,\n",
        "                fontsize=60,\n",
        "                color='white',\n",
        "                font='Arial-Bold',\n",
        "                size=(video.w * 0.8, None)\n",
        "            ).set_position('center').set_duration(3).set_start(1)\n",
        "\n",
        "            # Add fade effects\n",
        "            title_clip = title_clip.fadein(1).fadeout(1)\n",
        "\n",
        "            # Composite with main video\n",
        "            final_video = CompositeVideoClip([video, title_clip])\n",
        "            print(\"‚úÖ Title overlay added\")\n",
        "\n",
        "            return final_video\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Title overlay failed: {e}\")\n",
        "            return video\n",
        "\n",
        "    def _export_video(self, video, dream_script):\n",
        "        \"\"\"Export final video file\"\"\"\n",
        "        try:\n",
        "            title = dream_script.get(\"title\", \"dream\")\n",
        "            safe_title = \"\".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')\n",
        "\n",
        "            timestamp = int(time.time())\n",
        "            filename = f\"{safe_title}_{timestamp}.mp4\"\n",
        "            output_path = os.path.join(self.output_dir, filename)\n",
        "\n",
        "            print(f\"üì§ Exporting: {filename}\")\n",
        "            print(f\"   Duration: {video.duration:.1f}s\")\n",
        "\n",
        "            # Export with optimized settings\n",
        "            video.write_videofile(\n",
        "                output_path,\n",
        "                fps=24,\n",
        "                codec='libx264',\n",
        "                audio_codec='aac',\n",
        "                temp_audiofile=None,\n",
        "                remove_temp=True,\n",
        "                verbose=False,\n",
        "                logger=None\n",
        "            )\n",
        "\n",
        "            if os.path.exists(output_path):\n",
        "                file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
        "                print(f\"‚úÖ Video exported: {filename} ({file_size:.1f} MB)\")\n",
        "                return output_path\n",
        "            else:\n",
        "                print(\"‚ùå Video export failed\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Video export failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _create_video_placeholder(self, scenes, dream_script):\n",
        "        \"\"\"Create text placeholder when video creation fails\"\"\"\n",
        "        try:\n",
        "            timestamp = int(time.time())\n",
        "            filename = f\"video_description_{timestamp}.txt\"\n",
        "            filepath = os.path.join(self.output_dir, filename)\n",
        "\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(\"DREAM CINEMA PLACEHOLDER\\\\n\")\n",
        "                f.write(\"=\" * 50 + \"\\\\n\\\\n\")\n",
        "                f.write(f\"Title: {dream_script.get('title', 'Dream Vision')}\\\\n\")\n",
        "                f.write(f\"Generated: {time.ctime()}\\\\n\")\n",
        "                f.write(f\"Scenes: {len(scenes)}\\\\n\\\\n\")\n",
        "\n",
        "                for i, scene in enumerate(scenes):\n",
        "                    f.write(f\"Scene {i+1}:\\\\n\")\n",
        "                    f.write(f\"  {scene.get('description', 'Scene description')}\\\\n\\\\n\")\n",
        "\n",
        "            print(f\"üìù Placeholder created: {filename}\")\n",
        "            return filepath\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Placeholder creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "# Test function\n",
        "def test_video_assembler():\n",
        "    assembler = VideoAssembler()\n",
        "    print(\"‚úÖ VideoAssembler test completed\")\n",
        "    return True\n",
        "'''\n",
        "\n",
        "with open('video_assembler.py', 'w') as f:\n",
        "    f.write(video_assembler_code)\n",
        "\n",
        "print(\"‚úÖ video_assembler.py created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuBBn5hMbaS4",
        "outputId": "00bfe121-ad2c-46f8-9a3f-8d082ff49395"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ video_assembler.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß† Create Dream Processor Module\n",
        "dream_processor_code = '''\n",
        "import json\n",
        "import time\n",
        "\n",
        "class DreamProcessor:\n",
        "    \"\"\"Simple dream processing for scene generation\"\"\"\n",
        "\n",
        "    def __init__(self, api_key=None):\n",
        "        self.api_key = api_key\n",
        "        print(\"üß† DreamProcessor initialized\")\n",
        "\n",
        "    def expand_dream(self, dream_text, visual_style=\"fantasy\"):\n",
        "        \"\"\"Expand dream into structured scenes\"\"\"\n",
        "        try:\n",
        "            print(f\"üß† Processing dream: {len(dream_text)} characters\")\n",
        "\n",
        "            # Simple scene extraction (you could integrate with Groq/LLaMA here)\n",
        "            scenes = self._create_scenes_from_dream(dream_text, visual_style)\n",
        "\n",
        "            dream_script = {\n",
        "                \"title\": self._generate_title(dream_text),\n",
        "                \"narrator_text\": self._create_narration(dream_text),\n",
        "                \"scenes\": scenes,\n",
        "                \"visual_style\": visual_style,\n",
        "                \"generated_at\": time.ctime()\n",
        "            }\n",
        "\n",
        "            print(f\"‚úÖ Dream processed: {len(scenes)} scenes\")\n",
        "            return dream_script\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Dream processing failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _create_scenes_from_dream(self, dream_text, visual_style):\n",
        "        \"\"\"Create scene breakdown from dream description\"\"\"\n",
        "        # Simple scene creation - could be enhanced with AI\n",
        "        base_prompt = f\"{dream_text}, {visual_style} style\"\n",
        "\n",
        "        scenes = [\n",
        "            {\n",
        "                \"description\": f\"{base_prompt}, opening scene, establishing shot\",\n",
        "                \"mood\": \"mysterious\",\n",
        "                \"duration\": 4\n",
        "            },\n",
        "            {\n",
        "                \"description\": f\"{base_prompt}, detailed view, magical atmosphere\",\n",
        "                \"mood\": \"mystical\",\n",
        "                \"duration\": 4\n",
        "            },\n",
        "            {\n",
        "                \"description\": f\"{base_prompt}, climactic moment, dramatic lighting\",\n",
        "                \"mood\": \"dramatic\",\n",
        "                \"duration\": 4\n",
        "            },\n",
        "            {\n",
        "                \"description\": f\"{base_prompt}, peaceful resolution, ethereal glow\",\n",
        "                \"mood\": \"serene\",\n",
        "                \"duration\": 4\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        return scenes\n",
        "\n",
        "    def _generate_title(self, dream_text):\n",
        "        \"\"\"Generate title from dream text\"\"\"\n",
        "        # Simple title generation\n",
        "        words = dream_text.split()[:5]\n",
        "        return \" \".join(words).title()\n",
        "\n",
        "    def _create_narration(self, dream_text):\n",
        "        \"\"\"Create narration text\"\"\"\n",
        "        return f\"Enter a mystical realm where imagination becomes reality. {dream_text} Experience this dream journey through the magic of AI.\"\n",
        "\n",
        "# Test function\n",
        "def test_dream_processor():\n",
        "    processor = DreamProcessor()\n",
        "    test_script = processor.expand_dream(\"A magical forest with glowing trees\")\n",
        "    return test_script is not None\n",
        "'''\n",
        "\n",
        "with open('dream_processor.py', 'w') as f:\n",
        "    f.write(dream_processor_code)\n",
        "\n",
        "print(\"‚úÖ dream_processor.py created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV6cSqQtbclV",
        "outputId": "aefb1e8a-0f9b-4045-a8ea-c12fb0f7c1d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ dream_processor.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üé¨ Complete Dream Cinema App with Perfect Layout\n",
        "complete_app = '''\n",
        "# complete_dream_cinema.py\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "import time\n",
        "import io\n",
        "import os\n",
        "import warnings\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "import numpy as np\n",
        "\n",
        "# MoviePy imports for video assembly\n",
        "from moviepy.editor import (\n",
        "    ImageClip,\n",
        "    AudioFileClip,\n",
        "    concatenate_videoclips,\n",
        "    concatenate_audioclips,\n",
        "    CompositeVideoClip\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"üåå DreamScribe Ai\",\n",
        "    page_icon=\"üé¨\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# CSS for perfect layout\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .stTextArea > div > div > textarea {\n",
        "        width: 100% !important;\n",
        "    }\n",
        "    .main-header {\n",
        "        text-align: center;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        font-size: 3rem;\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .stButton > button {\n",
        "        width: 100%;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border-radius: 15px;\n",
        "        padding: 1rem;\n",
        "        font-weight: bold;\n",
        "        font-size: 1.2rem;\n",
        "        border: none;\n",
        "    }\n",
        "    .image-container {\n",
        "        border-radius: 15px;\n",
        "        overflow: hidden;\n",
        "        box-shadow: 0 8px 25px rgba(0,0,0,0.15);\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    \"\"\"Load Stable Diffusion model\"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    with st.spinner(\"üîÑ Loading AI model (first time takes 2-5 minutes)...\"):\n",
        "        pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "            \"dreamlike-art/dreamlike-diffusion-1.0\",\n",
        "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "            safety_checker=None,\n",
        "            requires_safety_checker=False\n",
        "        ).to(device)\n",
        "\n",
        "        if device == \"cuda\":\n",
        "            pipeline.enable_attention_slicing()\n",
        "            try:\n",
        "                pipeline.enable_xformers_memory_efficient_attention()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return pipeline, device\n",
        "\n",
        "\n",
        "def generate_image(prompt, pipeline, device):\n",
        "    \"\"\"Generate single image\"\"\"\n",
        "    try:\n",
        "        enhanced_prompt = f\"{prompt}, highly detailed, masterpiece, digital art, fantasy art\"\n",
        "        negative_prompt = \"blurry, low quality, distorted, ugly, bad anatomy, watermark, text\"\n",
        "\n",
        "        with torch.autocast(device):\n",
        "            result = pipeline(\n",
        "                prompt=enhanced_prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_inference_steps=25,\n",
        "                guidance_scale=7.5,\n",
        "                width=768,\n",
        "                height=768\n",
        "            )\n",
        "\n",
        "        return result.images[0] if result.images else None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Image generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_audio_narration(text, voice_style=\"mystical\"):\n",
        "    \"\"\"Create audio narration\"\"\"\n",
        "    try:\n",
        "        voice_configs = {\n",
        "            \"mystical\": {\"tld\": \"co.uk\", \"slow\": True},\n",
        "            \"dramatic\": {\"tld\": \"com\", \"slow\": False},\n",
        "            \"gentle\": {\"tld\": \"ca\", \"slow\": True},\n",
        "            \"epic\": {\"tld\": \"com.au\", \"slow\": False}\n",
        "        }\n",
        "\n",
        "        config = voice_configs.get(voice_style, voice_configs[\"mystical\"])\n",
        "        tts = gTTS(text=text, lang=\"en\", slow=config[\"slow\"], tld=config[\"tld\"])\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_file:\n",
        "            tts.save(tmp_file.name)\n",
        "            return tmp_file.name\n",
        "    except Exception as e:\n",
        "        st.error(f\"Audio generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_dream_scenes(dream_text, visual_style):\n",
        "    \"\"\"Create multiple scenes from dream description\"\"\"\n",
        "    base_prompt = f\"{dream_text}, {visual_style} style\"\n",
        "\n",
        "    scenes = [\n",
        "        {\"description\": f\"{base_prompt}, opening scene, establishing shot, cinematic lighting\", \"duration\": 4},\n",
        "        {\"description\": f\"{base_prompt}, detailed close-up view, magical atmosphere, ethereal glow\", \"duration\": 4},\n",
        "        {\"description\": f\"{base_prompt}, dramatic wide angle, epic composition, dynamic lighting\", \"duration\": 4},\n",
        "        {\"description\": f\"{base_prompt}, peaceful resolution, soft lighting, serene atmosphere\", \"duration\": 4}\n",
        "    ]\n",
        "\n",
        "    return scenes\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Robust assemble_video function\n",
        "# ------------------------------\n",
        "def assemble_video(images, audio_path=None, duration_per_image=4, output_file=None, target_height=720):\n",
        "    \"\"\"\n",
        "    Assemble an MP4 video from a list of PIL Images or image file paths.\n",
        "    - images: list of PIL.Image.Image objects or file path strings.\n",
        "    - audio_path: optional path to narration mp3.\n",
        "    - duration_per_image: fallback per-image duration (ignored if scenes supply per-image durations).\n",
        "    - output_file: optional output path; if None a temp file will be used.\n",
        "    - target_height: desired video height (maintains aspect ratio).\n",
        "    Returns the path to the created .mp4 file or None on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Prepare temporary output path\n",
        "        if output_file is None:\n",
        "            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
        "            output_path = tmp.name\n",
        "            tmp.close()\n",
        "        else:\n",
        "            output_path = output_file\n",
        "\n",
        "        # Ensure we have usable file paths for ImageClip (moviepy handles paths better)\n",
        "        temp_saved_paths = []\n",
        "        created_temp_files = []\n",
        "        for idx, im in enumerate(images):\n",
        "            if isinstance(im, str) and os.path.exists(im):\n",
        "                temp_saved_paths.append(im)\n",
        "                continue\n",
        "\n",
        "            # If image is a PIL image object, save to temp file\n",
        "            if hasattr(im, \"save\"):\n",
        "                tf = tempfile.NamedTemporaryFile(delete=False, suffix=f\"_scene_{idx}.png\")\n",
        "                im_rgb = im.convert(\"RGB\")\n",
        "                im_rgb.save(tf.name, format=\"PNG\")\n",
        "                temp_saved_paths.append(tf.name)\n",
        "                created_temp_files.append(tf.name)\n",
        "                tf.close()\n",
        "                continue\n",
        "\n",
        "            # If image is a numpy array\n",
        "            if isinstance(im, np.ndarray):\n",
        "                tf = tempfile.NamedTemporaryFile(delete=False, suffix=f\"_scene_{idx}.png\")\n",
        "                Image.fromarray(im).save(tf.name, format=\"PNG\")\n",
        "                temp_saved_paths.append(tf.name)\n",
        "                created_temp_files.append(tf.name)\n",
        "                tf.close()\n",
        "                continue\n",
        "\n",
        "            # Unsupported type\n",
        "            st.warning(f\"Unsupported image type for scene {idx+1}, skipping.\")\n",
        "\n",
        "        if not temp_saved_paths:\n",
        "            st.error(\"No valid images to assemble into a video.\")\n",
        "            # cleanup created temp files (if any)\n",
        "            for p in created_temp_files:\n",
        "                try:\n",
        "                    os.remove(p)\n",
        "                except:\n",
        "                    pass\n",
        "            return None\n",
        "\n",
        "        # Create ImageClip list\n",
        "        clips = []\n",
        "        for img_path in temp_saved_paths:\n",
        "            try:\n",
        "                clip = ImageClip(img_path)\n",
        "                # Resize maintaining aspect ratio by target_height\n",
        "                try:\n",
        "                    clip = clip.resize(height=target_height)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                clip = clip.set_duration(duration_per_image)\n",
        "                clips.append(clip)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Failed to create clip for {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not clips:\n",
        "            st.error(\"Failed to create any video clips from images.\")\n",
        "            for p in created_temp_files:\n",
        "                try:\n",
        "                    os.remove(p)\n",
        "                except:\n",
        "                    pass\n",
        "            return None\n",
        "\n",
        "        # Concatenate into final video clip\n",
        "        final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "        # Attach audio if available\n",
        "        if audio_path and os.path.exists(audio_path):\n",
        "            try:\n",
        "                audio = AudioFileClip(audio_path)\n",
        "                # Sync audio length to video\n",
        "                if audio.duration > final_video.duration:\n",
        "                    audio = audio.subclip(0, final_video.duration)\n",
        "                elif audio.duration < final_video.duration:\n",
        "                    loops_needed = int(final_video.duration / audio.duration) + 1\n",
        "                    audio = concatenate_audioclips([audio] * loops_needed).subclip(0, final_video.duration)\n",
        "\n",
        "                final_video = final_video.set_audio(audio)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Audio integration failed: {e}  ‚Äî proceeding without audio.\")\n",
        "\n",
        "        # Export final video (moviepy uses ffmpeg; ensure ffmpeg is installed in environment)\n",
        "        # Use reasonable settings for browser playback\n",
        "        final_video.write_videofile(\n",
        "            output_path,\n",
        "            fps=24,\n",
        "            codec='libx264',\n",
        "            audio_codec='aac' if (audio_path and os.path.exists(audio_path)) else None,\n",
        "            temp_audiofile=os.path.join(tempfile.gettempdir(), \"temp-audio.m4a\"),\n",
        "            remove_temp=True,\n",
        "            threads=4,\n",
        "            verbose=False,\n",
        "            logger=None\n",
        "        )\n",
        "\n",
        "        # Clean up created temporary image files\n",
        "        for p in created_temp_files:\n",
        "            try:\n",
        "                os.remove(p)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
        "            return output_path\n",
        "        else:\n",
        "            st.error(\"Video export failed or produced empty file.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Video assembly error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# Main Streamlit app (unchanged UI & flow)\n",
        "# ===========================================\n",
        "def main():\n",
        "    # Header\n",
        "    st.markdown('<h1 class=\"main-header\">üåå DreamScribe Ai </h1>', unsafe_allow_html=True)\n",
        "    st.markdown('<p style=\"text-align: center; font-size: 1.3rem; color: #666;\">Transform your dreams into stunning AI-generated cinema</p>', unsafe_allow_html=True)\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        pipeline, device = load_model()\n",
        "        st.success(f\"‚úÖ AI model loaded successfully on {device.upper()}!\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Failed to load model: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    # ===========================================\n",
        "    # MAIN INPUT SECTION - FULL WIDTH\n",
        "    # ===========================================\n",
        "\n",
        "    st.markdown(\"# üìù Create Your Dream Cinema\")\n",
        "\n",
        "    # Full-width dream description\n",
        "    dream_description = st.text_area(\n",
        "        \"Describe your dream:\",\n",
        "        height=200,\n",
        "        placeholder=\"A magical library where books have wings and fly around like colorful birds, with crystal walls reflecting infinite stories and glowing runes that change with each story told...\",\n",
        "        help=\"Be as detailed and creative as possible! The more vivid your description, the better your results.\",\n",
        "        key=\"dream_input\"\n",
        "    )\n",
        "\n",
        "    # Style options in columns\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        visual_style = st.selectbox(\n",
        "            \"üé® Visual Style:\",\n",
        "            [\n",
        "                \"fantasy magical\",\n",
        "                \"sci-fi futuristic\",\n",
        "                \"nature ethereal\",\n",
        "                \"cosmic celestial\",\n",
        "                \"gothic mysterious\",\n",
        "                \"anime stylized\"\n",
        "            ],\n",
        "            help=\"Choose the artistic style for your dream visualization\"\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        voice_style = st.selectbox(\n",
        "            \"üéôÔ∏è Narrator Voice:\",\n",
        "            [\n",
        "                \"mystical\",\n",
        "                \"dramatic\",\n",
        "                \"gentle\",\n",
        "                \"epic\"\n",
        "            ],\n",
        "            help=\"Select the voice style for narration\"\n",
        "        )\n",
        "\n",
        "    # Additional options\n",
        "    col3, col4 = st.columns(2)\n",
        "\n",
        "    with col3:\n",
        "        num_scenes = st.slider(\"üé≠ Number of Scenes:\", 2, 6, 4)\n",
        "\n",
        "    with col4:\n",
        "        include_narration = st.checkbox(\"üéôÔ∏è Include Narration\", value=True)\n",
        "\n",
        "    # Generate button\n",
        "    generate_clicked = st.button(\"üé¨ Create Dream Cinema\", type=\"primary\")\n",
        "\n",
        "    # ===========================================\n",
        "    # GENERATION AND RESULTS\n",
        "    # ===========================================\n",
        "\n",
        "    if generate_clicked:\n",
        "        if not dream_description.strip():\n",
        "            st.error(\"‚ùå Please describe your dream first!\")\n",
        "        else:\n",
        "            # Progress tracking\n",
        "            progress_bar = st.progress(0)\n",
        "            status_text = st.empty()\n",
        "\n",
        "            try:\n",
        "                # Step 1: Create scene descriptions\n",
        "                status_text.text(\"üß† Creating dream scenes...\")\n",
        "                progress_bar.progress(10)\n",
        "\n",
        "                # create scene dicts with durations (the UI slider controls number of scenes)\n",
        "                base_scenes = create_dream_scenes(dream_description, visual_style)\n",
        "                scene_prompts = base_scenes[:num_scenes]\n",
        "\n",
        "                # Step 2: Generate images\n",
        "                status_text.text(\"üé® Generating dream visuals...\")\n",
        "                progress_bar.progress(30)\n",
        "\n",
        "                generated_images = []\n",
        "\n",
        "                for i, scene in enumerate(scene_prompts):\n",
        "                    scene_progress = 30 + (50 * (i + 1) / len(scene_prompts))\n",
        "                    progress_bar.progress(int(scene_progress))\n",
        "                    status_text.text(f\"üé® Creating scene {i+1}/{len(scene_prompts)}...\")\n",
        "\n",
        "                    image = generate_image(scene[\"description\"], pipeline, device) if isinstance(scene, dict) else generate_image(scene, pipeline, device)\n",
        "                    if image:\n",
        "                        generated_images.append(image)\n",
        "\n",
        "                    # Memory cleanup\n",
        "                    if device == \"cuda\":\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                # Step 3: Create narration\n",
        "                audio_path = None\n",
        "                if include_narration and generated_images:\n",
        "                    status_text.text(\"üéôÔ∏è Creating mystical narration...\")\n",
        "                    progress_bar.progress(85)\n",
        "\n",
        "                    narration_text = f\"Welcome to a realm of dreams and wonder. {dream_description} Experience this magical journey through the power of imagination.\"\n",
        "                    audio_path = create_audio_narration(narration_text, voice_style)\n",
        "\n",
        "                progress_bar.progress(95)\n",
        "                status_text.text(\"üé¨ Assembling video...\")\n",
        "\n",
        "                # Step 4: Assemble video (this will convert images and attach audio)\n",
        "                # Use duration from scene dicts if provided; fallback to 4 seconds per frame\n",
        "                per_image_duration = 4\n",
        "                # Produce the video and show / download in UI\n",
        "                video_path = assemble_video(generated_images, audio_path=audio_path, duration_per_image=per_image_duration)\n",
        "\n",
        "                progress_bar.progress(100)\n",
        "                status_text.text(\"‚úÖ Dream cinema complete!\")\n",
        "\n",
        "                # ===========================================\n",
        "                # DISPLAY RESULTS - 2x2 GRID\n",
        "                # ===========================================\n",
        "\n",
        "                if generated_images:\n",
        "                    st.markdown(\"## üé¨ Your Dream Cinema\")\n",
        "                    st.success(f\"üéâ Generated {len(generated_images)} magical scenes!\")\n",
        "\n",
        "                    # Display images in 2-column grid\n",
        "                    cols = st.columns(2)\n",
        "\n",
        "                    for idx, image in enumerate(generated_images):\n",
        "                        with cols[idx % 2]:\n",
        "                            # Image with styling\n",
        "                            st.markdown('<div class=\"image-container\">', unsafe_allow_html=True)\n",
        "                            st.image(\n",
        "                                image,\n",
        "                                caption=f\"Scene {idx+1}\",\n",
        "                                use_container_width=True\n",
        "                            )\n",
        "                            st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "                            # Download button\n",
        "                            img_buffer = io.BytesIO()\n",
        "                            image.save(img_buffer, format='PNG')\n",
        "                            st.download_button(\n",
        "                                f\"üì• Download Scene {idx+1}\",\n",
        "                                data=img_buffer.getvalue(),\n",
        "                                file_name=f\"dream_scene_{idx+1}_{int(time.time())}.png\",\n",
        "                                mime=\"image/png\",\n",
        "                                key=f\"download_{idx}\",\n",
        "                                use_container_width=True\n",
        "                            )\n",
        "\n",
        "                    # Audio player\n",
        "                    if audio_path and os.path.exists(audio_path):\n",
        "                        st.markdown(\"### üéôÔ∏è Dream Narration\")\n",
        "                        st.audio(audio_path)\n",
        "\n",
        "                        # Audio download\n",
        "                        with open(audio_path, 'rb') as f:\n",
        "                            st.download_button(\n",
        "                                \"üì• Download Narration\",\n",
        "                                data=f.read(),\n",
        "                                file_name=f\"dream_narration_{int(time.time())}.mp3\",\n",
        "                                mime=\"audio/mp3\"\n",
        "                            )\n",
        "\n",
        "                    # Video player & download\n",
        "                    if video_path and os.path.exists(video_path):\n",
        "                        st.markdown(\"### üé• Final Dream Cinema Video\")\n",
        "                        st.video(video_path)\n",
        "                        with open(video_path, \"rb\") as f:\n",
        "                            st.download_button(\"üì• Download Video\", f.read(), file_name=f\"dream_cinema_{int(time.time())}.mp4\", mime=\"video/mp4\")\n",
        "\n",
        "                    st.balloons()\n",
        "\n",
        "                else:\n",
        "                    st.error(\"‚ùå No images were generated. Please try again.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"‚ùå Generation failed: {e}\")\n",
        "                progress_bar.progress(0)\n",
        "                status_text.text(\"‚ùå Generation failed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "'''\n",
        "\n",
        "# Save the complete app\n",
        "with open('complete_dream_cinema.py', 'w') as f:\n",
        "    f.write(complete_app)\n",
        "\n",
        "print(\"‚úÖ Complete Dream Cinema app created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TT_Yq6KbeaM",
        "outputId": "2e9d4f3f-4ff5-4032-ee5d-cf4db8592c6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Complete Dream Cinema app created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Launch Complete Dream Cinema App\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Clean up existing processes\n",
        "!pkill -f streamlit\n",
        "!killall ngrok\n",
        "time.sleep(3)\n",
        "\n",
        "# Launch the complete app\n",
        "def run_complete_app():\n",
        "    subprocess.run(['streamlit', 'run', 'complete_dream_cinema.py', '--server.port=8501', '--server.address=0.0.0.0'])\n",
        "\n",
        "print(\"üöÄ Starting Complete Dream Cinema Studio...\")\n",
        "app_thread = threading.Thread(target=run_complete_app)\n",
        "app_thread.daemon = True\n",
        "app_thread.start()\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "# Create tunnel\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"üåê Complete Dream Cinema Studio: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to create tunnel: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-JbHDzebvqw",
        "outputId": "21e07e69-94cf-4bc6-fef6-575c0edc7cbf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Complete Dream Cinema Studio...\n",
            "üåê Complete Dream Cinema Studio: NgrokTunnel: \"https://2d8894f4a727.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "üé¨ Features:\n",
            "   üìù Full-width dream input\n",
            "   üé® AI image generation (Stable Diffusion)\n",
            "   üéôÔ∏è Voice narration (gTTS)\n",
            "   üñºÔ∏è 2x2 image grid display\n",
            "   üì• Individual downloads\n",
            "   üéµ Audio playback\n",
            "   ‚ú® Professional styling\n"
          ]
        }
      ]
    }
  ]
}